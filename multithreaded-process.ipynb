{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import subprocess\n",
    "import xml.sax\n",
    "import mwparserfromhell\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "from multiprocessing import Pool \n",
    "import tqdm \n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    \"\"\"Content handler for Wiki XML data using SAX\"\"\"\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._current_tag = None\n",
    "        self._pages = []\n",
    "\n",
    "    def characters(self, content):\n",
    "        \"\"\"Characters between opening and closing tags\"\"\"\n",
    "        if self._current_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        \"\"\"Opening tag of element\"\"\"\n",
    "        if name in ('title', 'text'):\n",
    "            self._current_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        \"\"\"Closing tag of element\"\"\"\n",
    "        if name == self._current_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "\n",
    "        if name == 'page':\n",
    "            self._pages.append((self._values['title'], self._values['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_links(data_path, save = True):\n",
    "    handler = WikiXmlHandler()\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(handler)\n",
    "\n",
    "    for i, line in enumerate(subprocess.Popen(['bzcat'], \n",
    "                             stdin = open(f'./partitioned-data/{data_path}'), \n",
    "                             stdout = subprocess.PIPE).stdout):\n",
    "        try:\n",
    "            parser.feed(line)\n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    if save:\n",
    "        new_data_path = data_path[0:data_path.find('xml')-1] + '-' + data_path[data_path.find('xml') + 4:-4]\n",
    "        m = {}\n",
    "        for page in handler._pages:\n",
    "            wikipage = mwparserfromhell.parse(page[1])\n",
    "            wikilinks = [str(x.title) for x in wikipage.filter_wikilinks()]\n",
    "            m[page[0]] = wikilinks\n",
    "            \n",
    "        with open(f'./json-data/{new_data_path}.json', 'w') as fout:\n",
    "            fout.write(json.dumps(m))\n",
    "\n",
    "        partition_dir = './json-data'\n",
    "        print(f'{ len(os.listdir(partition_dir)) } files processed.', end = '\\r')\n",
    "\n",
    "    # Memory management\n",
    "    del handler\n",
    "    del parser\n",
    "    gc.collect()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enwiki-latest-pages-articles26.xml-p42567203p42663461.bz2',\n",
       " 'enwiki-latest-pages-articles24.xml-p33503451p33952815.bz2',\n",
       " 'enwiki-latest-pages-articles23.xml-p29823661p30503450.bz2',\n",
       " 'enwiki-latest-pages-articles1.xml-p1p30303.bz2',\n",
       " 'enwiki-latest-pages-articles20.xml-p20254736p21222156.bz2']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = os.listdir('./partitioned-data')\n",
    "partitions.remove('.DS_Store')\n",
    "for data_path in partitions:\n",
    "    if data_path[0:data_path.find('xml')-1] + '-' + data_path[data_path.find('xml') + 4:-4] + '.json' in os.listdir('./json-data'):\n",
    "        partitions.remove(data_path)\n",
    "        \n",
    "partitions = sorted(partitions, key = lambda x: os.path.getsize(f'./partitioned-data/{x}'))\n",
    "partitions = partitions[0:5]\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool of workers to execute processes\n",
    "pool = Pool(processes = 8)\n",
    "\n",
    "start = timer()\n",
    "\n",
    "# Map (service, tasks), applies function to each partition\n",
    "results = pool.map(find_links, partitions)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end = timer()\n",
    "print(f'{end - start} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
